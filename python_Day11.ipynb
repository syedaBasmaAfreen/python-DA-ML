{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPP/mZChJdsH8xhIGWmD2C6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syedaBasmaAfreen/python-DA-ML/blob/main/python_Day11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⌨ Day11"
      ],
      "metadata": {
        "id": "XUkmm1l_3fKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is NLTK?\n",
        "\n",
        "The Natural Language Toolkit `(NLTK)`is a package in python that provides libraries for different text processing techniques, such as classification, tokenization, stemming and tagging.\n",
        "\n",
        "`NLTK corpus`\n",
        "\n",
        "Punkt: This tokenizer divides a text into a list of sentences to build a model for abbreviation words, collocations and words with sentences.\n",
        "\n",
        "Wordnet: WordNet is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets).\n",
        "\n",
        "averaged_perceptron_tagger: It is used for tagging words with their parts of speech (POS)\n",
        "\n",
        "tagset: The tagset consists of the following tags:\n",
        "\n",
        "VB - verbs (all tenses and modes)\n",
        "\n",
        "NN - nouns (common and proper)\n",
        "\n",
        "PRON - pronouns\n",
        "\n",
        "ADJ - adjectives\n",
        "\n",
        "ADV - adverbs\n",
        "ADV - adverbs\n",
        "\n",
        "ADP - adpositions (prepositions and postpositions)\n",
        "\n",
        "CONJ - conjunctions\n",
        "\n",
        "DET - determiners\n",
        "\n",
        "NUM - cardinal numbers\n",
        "\n",
        "PRT - particles or other function words\n",
        "\n",
        "IN - preposition/subordinating conjunction\n",
        "\n",
        "NNS - noun plural ‘desks’\n",
        "\n",
        "JJ - adjective ‘big’\n",
        "\n",
        "VBP - verb, sing. present, non-3d take\n",
        "\n",
        "DT - determiner"
      ],
      "metadata": {
        "id": "hNXXSkjcvWhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "s1=\"lists listed Listings Listed list\"\n",
        "#normalization\n",
        "words1=s1.lower().split()\n",
        "words1\n",
        "# porter=nltk.PorterStemmer()\n",
        "# [porter.stem(t) for t in words1]\n",
        "#limitation is used for meaningful root words"
      ],
      "metadata": {
        "id": "fg9BaB0Lvf08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "porter=nltk.PorterStemmer()\n",
        "[porter.stem(t) for t in words1]"
      ],
      "metadata": {
        "id": "DZbIk1LIxslF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('udhr')\n",
        "udhr=nltk.corpus.udhr.words(\"English-Latin1\")\n",
        "udhr[:20]\n",
        "#udhr"
      ],
      "metadata": {
        "id": "eNYqR7jvx5y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "porter=nltk.PorterStemmer()\n",
        "[porter.stem(t) for t in udhr[:20]]"
      ],
      "metadata": {
        "id": "hPsQ8ZX-0Hcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#limitation is used for meaningful root words\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "Lemma=nltk.WordNetLemmatizer()\n",
        "[Lemma.lemmatize(t) for t in udhr[:20]]"
      ],
      "metadata": {
        "id": "agFjx_Ev0TQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "s1=\"children shouldn't drink any sugary drinks before bedtime.\"\n",
        "nltk.word_tokenize(s1)"
      ],
      "metadata": {
        "id": "DcWRbzbs1P5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "s1=\"children shouldn't drink any sugary drinks before bedtime.\"\n",
        "#nltk.sentence_tokenize(s1) when we have multiple sentence"
      ],
      "metadata": {
        "id": "RlM6UUSI1P1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "s1=\"children shouldn't drink any sugary drinks before bedtime.\"\n",
        "s2=nltk.word_tokenize(s1)\n",
        "nltk.pos_tag(s2)"
      ],
      "metadata": {
        "id": "wXntEdvb2uUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import string\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "XAdEShiZ5gQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specify the url\n",
        "url=\"http://shakespeare.mit.edu/allswell/full.html\"\n"
      ],
      "metadata": {
        "id": "griXsEUT4o0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a response\n",
        "try:\n",
        "    r = requests.get(url)\n",
        "    soup = bs(r.content , 'lxml')\n",
        "except:\n",
        "     pass"
      ],
      "metadata": {
        "id": "66WAdMqN6Sa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = soup.get_text()\n",
        "text\n"
      ],
      "metadata": {
        "id": "0rT4zC7768xP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Tokenization`"
      ],
      "metadata": {
        "id": "I_JFnczL8w-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download()"
      ],
      "metadata": {
        "id": "gEbjuzNV8zoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.lower()\n",
        "text = text.replace('\\n','')"
      ],
      "metadata": {
        "id": "yMU9Wx6o7hel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "id": "RVueNiUx7_e9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Sentence  level tokenization`\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XcXKKk1X8jMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(text)\n",
        "sentences"
      ],
      "metadata": {
        "id": "NV4s1zyt7_O-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentences)"
      ],
      "metadata": {
        "id": "jsDYHHn3-Uxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[0]"
      ],
      "metadata": {
        "id": "tIaODVXu-XVQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}